{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6417582,"sourceType":"datasetVersion","datasetId":3701557},{"sourceId":6675703,"sourceType":"datasetVersion","datasetId":3851533}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:07.239133Z","iopub.execute_input":"2023-10-15T06:00:07.23941Z","iopub.status.idle":"2023-10-15T06:00:15.77952Z","shell.execute_reply.started":"2023-10-15T06:00:07.239388Z","shell.execute_reply":"2023-10-15T06:00:15.778557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert Images in directory into Dataset\nwe can use `tf.keras.preprocessing.image_dataset_from_directory` to convert the data into dataset so we can train the models out of the box","metadata":{}},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    \"/kaggle/input/indian-medicinal-leaves-dataset/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset\",\n    shuffle=True,\n    batch_size=32,\n    image_size=(299, 299),\n)\n\nlabels = dataset.class_names\nlabels","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:15.784441Z","iopub.execute_input":"2023-10-15T06:00:15.78684Z","iopub.status.idle":"2023-10-15T06:00:20.444299Z","shell.execute_reply.started":"2023-10-15T06:00:15.786806Z","shell.execute_reply":"2023-10-15T06:00:20.443368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nfor image_batch, labels_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(labels_batch.numpy())\n    break","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:20.445793Z","iopub.execute_input":"2023-10-15T06:00:20.446453Z","iopub.status.idle":"2023-10-15T06:00:30.56163Z","shell.execute_reply.started":"2023-10-15T06:00:20.446419Z","shell.execute_reply":"2023-10-15T06:00:30.560637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train test split\ntrain_size = int(0.8 * len(dataset))\ntest_size = int(0.2 * len(dataset))\ntrain_size, test_size","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:30.564436Z","iopub.execute_input":"2023-10-15T06:00:30.56499Z","iopub.status.idle":"2023-10-15T06:00:30.573691Z","shell.execute_reply.started":"2023-10-15T06:00:30.564957Z","shell.execute_reply":"2023-10-15T06:00:30.572772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train, Test, Validate\npartition the data into train test and validation datasets","metadata":{}},{"cell_type":"code","source":"def get_dataset_partisions_tf(ds, train_split=0.8, test_split=0.2, shuffle=True, shuffle_size=10000):\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed=12)\n    train_size = int(train_split * len(ds))\n    test_size = int(test_split * len(ds))\n    train_ds = ds.take(train_size)\n    test_ds = ds.skip(train_size)\n    val_ds = test_ds.skip(test_size)\n    test_ds = test_ds.take(test_size)\n    return train_ds, test_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:30.575237Z","iopub.execute_input":"2023-10-15T06:00:30.57563Z","iopub.status.idle":"2023-10-15T06:00:30.58389Z","shell.execute_reply.started":"2023-10-15T06:00:30.575601Z","shell.execute_reply":"2023-10-15T06:00:30.582873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, test_ds, val_ds = get_dataset_partisions_tf(dataset)\nlen(train_ds), len(test_ds), len(val_ds)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:30.585342Z","iopub.execute_input":"2023-10-15T06:00:30.585881Z","iopub.status.idle":"2023-10-15T06:00:30.606412Z","shell.execute_reply.started":"2023-10-15T06:00:30.585851Z","shell.execute_reply":"2023-10-15T06:00:30.605306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Resize and Normalize\n- Xception models takes the image input as 299x299 pixels so converting into the trainable format is necessary\n- The Images are to be normalized before to train accurately and efficiently","metadata":{}},{"cell_type":"code","source":"resize_and_rescale = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Resizing(299, 299),\n    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n])","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:30.607515Z","iopub.execute_input":"2023-10-15T06:00:30.607871Z","iopub.status.idle":"2023-10-15T06:00:30.62526Z","shell.execute_reply.started":"2023-10-15T06:00:30.60782Z","shell.execute_reply":"2023-10-15T06:00:30.624422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Download the Xception model predefined weights from tensorflow into your working environment","metadata":{}},{"cell_type":"code","source":"# train using Xception\nbase_model = tf.keras.applications.InceptionV3(\n    weights='imagenet',\n    input_shape=(299, 299, 3),\n    include_top=False,\n    pooling='avg',\n    classifier_activation='softmax',\n    classes=len(labels)\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:30.626545Z","iopub.execute_input":"2023-10-15T06:00:30.627343Z","iopub.status.idle":"2023-10-15T06:00:36.462535Z","shell.execute_reply.started":"2023-10-15T06:00:30.627313Z","shell.execute_reply":"2023-10-15T06:00:36.461544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = False\n\ninputs = tf.keras.Input(shape=(299, 299, 3))\nx = resize_and_rescale(inputs)\nx = base_model(x, training=False)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    batch_size=32,\n    epochs=20\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-15T06:00:36.46388Z","iopub.execute_input":"2023-10-15T06:00:36.46425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict with new images\nimport numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/alo.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\n\n\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict with new images\nimport numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/bamboo.jpeg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/betel-leaf-1024x1024.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/bamboo.jpeg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/doddapatre.jpg', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nimg = tf.keras.preprocessing.image.load_img(\n    '/kaggle/input/test-medicinal-leaves/tulsi-leaves-t-cut-500x500.jpg.webp', target_size=(299, 299)\n)\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create a batch\npredictions = model.predict(img_array)\nscore = tf.nn.sigmoid(predictions[0])\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(labels[np.argmax(score)], 100 * np.max(score))\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot accuracy and loss\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model_avg_20_inception.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}